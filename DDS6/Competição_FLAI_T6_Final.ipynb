{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Competição_FLAI_T6_Final",
      "provenance": [],
      "collapsed_sections": [
        "yuT9sWe5QTEs",
        "EavdZobRH_fy",
        "5XGamhtNRu44",
        "EQjJfHPJxnz7",
        "QdaaGx05x8iR",
        "59_GlJEYmvxn",
        "C23xYWgDrz8F",
        "A2K7HCyBvT4y",
        "67z-OUchvjy1",
        "8MHp5jZ4-VVP",
        "YUNgfYqC7NMT",
        "o1jWdBqCMxYv",
        "7ZWR_ujEx5oP",
        "5_sUtW6brJRo",
        "Eo70AnvqgdYV",
        "txXoMrZUDvsN",
        "mm4qYywkDx5W",
        "MAClGXQ5xWyI",
        "SA7lBMt0BL5b",
        "U5Id2Xi4c5Tg",
        "GPT3qzdmc9Cb",
        "XpE2ZM_SrCvL",
        "QUBkCUArTMzb",
        "TudAqI9ezBfq",
        "UI6_YqgBpNvo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkunyosi/FLAI-CompeticaoML/blob/learning/Competi%C3%A7%C3%A3o_FLAI_T6_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HUGboZ_vC9d"
      },
      "source": [
        "# 6ª Competição FLAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuT9sWe5QTEs"
      },
      "source": [
        "## A competição"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Tj2qoqGu8_"
      },
      "source": [
        "*   Dado um conjunto de dados de funcionários de uma empresa, deseja-se prever quais são aqueles que irão sair da empresa nos próximos 2 anos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA0IEs8qGU2a"
      },
      "source": [
        "### Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPKiemBgGzaB"
      },
      "source": [
        "*   Escolaridade: grau de escolaridade do funcionário.\n",
        "*   Entrada: ano de entrada na empresa. \n",
        "*   Cidade: cidade em que o funcionário mora.\n",
        "*   Salário: classe de salário que o funcionário recebe (1 > 2 > *   3). \n",
        "*   Idade: idade em anos do funcionário. \n",
        "*   Sexo: sexo do funcionário. \n",
        "*   Projeto: se o funcionário já ficou sem projetos por 1 mês ou mais. \n",
        "*   Experiência: anos de experiência que o funcionário possui na área que atua.\n",
        "*   Feedbacks: número de feedbacks negativos recebidos pelo funcionário.\n",
        "*   Saiu: se o funcionário saiu da empresa antes de 2 anos de casa (0: não, 1: sim)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEP1_Ra4HSPt"
      },
      "source": [
        "*   Conjunto de dados de treinamento: (2916, 10) contém a variável resposta “Saiu”. [Dados de treino](https://raw.githubusercontent.com/mkunyosi/FLAI-CompeticaoML/learning/treino.csv)\n",
        "*   Conjunto de dados de teste: (1737, 9) não contém a variável resposta, a qual deve ser predita. [Dados de teste](https://raw.githubusercontent.com/mkunyosi/FLAI-CompeticaoML/learning/teste.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PREgZ8gVG473"
      },
      "source": [
        "### Métrica alvo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpdzySSvG9tj"
      },
      "source": [
        "F1-SCORE - o modelo com o melhor índice leva a competição!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emFJMPR8KxqW"
      },
      "source": [
        "### Período para submissões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu8PcYuWM7OD"
      },
      "source": [
        "Início: 29/10/2021 </br>\n",
        "Término: 28/11/2021 - 20:00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EavdZobRH_fy"
      },
      "source": [
        "## Preparação do ambiente de trabalho"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG5OkntHijxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f467965-9b28-4879-abd9-3fe2ffdd2163"
      },
      "source": [
        "# executa este comando e depois reinicia o ambiente de execução no colab, para que o pycaret funcione. Adicionalemnte, inclui \n",
        "# o sweetviz para contribuir na Análise Exploratória de Dados.\n",
        "!pip install pycaret\n",
        "!pip install sweetviz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycaret\n",
            "  Downloading pycaret-2.3.5-py3-none-any.whl (288 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 92 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 122 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 133 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 163 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 174 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 184 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 194 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 204 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 215 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 235 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 245 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 256 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 266 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 276 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 286 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 288 kB 23.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.11.1-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.0)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Collecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.5)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.22.0-py3-none-any.whl (15.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.5 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting umap-learn\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 40.2 MB/s \n",
            "\u001b[?25hCollecting pyod\n",
            "  Downloading pyod-0.9.5.tar.gz (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 45.0 MB/s \n",
            "\u001b[?25hCollecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 36.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.5)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.4.1)\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "  Downloading pandas_profiling-3.1.0-py2.py3-none-any.whl (261 kB)\n",
            "\u001b[K     |████████████████████████████████| 261 kB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.post1)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Collecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 34.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Collecting imbalanced-learn==0.7.0\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret) (3.0.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.37.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (3.0.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.9.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Collecting phik>=0.11.1\n",
            "  Downloading phik-0.12.0-cp37-cp37m-manylinux2010_x86_64.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 37.6 MB/s \n",
            "\u001b[?25hCollecting multimethod>=1.4\n",
            "  Downloading multimethod-1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.62.3)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[K     |████████████████████████████████| 303 kB 47.0 MB/s \n",
            "\u001b[?25hCollecting tangled-up-in-unicode==0.1.0\n",
            "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 41.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.0.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting visions[type_image_path]==0.7.4\n",
            "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 37.3 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 658 kB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (21.2.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (2.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 32.9 MB/s \n",
            "\u001b[?25hCollecting scipy<=1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8.1->pandas-profiling>=2.8.0->pycaret) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (3.6.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.12.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.2)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.27)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.12.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.7.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 42.5 MB/s \n",
            "\u001b[?25hCollecting funcy\n",
            "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 42.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 23.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.5.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 25.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin, imagehash, alembic, databricks-cli, pyLDAvis, pyod, umap-learn, pynndescent\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=dd400ffc0eb8b743735d117e2f1c834fa32d3079d841db9c369084583cf1ec16\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295207 sha256=87a1ec218ffdeac6befa9ff2123c63a255abc85b91fe95df471a1452344059b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=312ad4a70a9b8d621b62f647f4443eb8b7c43272f1ca587124f4aed75ef4b30c\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=7d8dfc0d5f60555a63b19038ce55e7878a936528817a698be656216e7c7c03b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135618 sha256=4dd8c6eb4efdfb6f6ae767332c230be2c5c6f4eb5c01190412f0d780ef555141\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b1/9b/560ac1931796b7303f7b517b949d2d31a4fbc512aad3b9f284\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.5-py3-none-any.whl size=132699 sha256=1d8cdd11fbf0664a22140044bf8ca7f5ed37b7f9b972898a589cc7e0748ae147\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/bb/b7/62b60fb451b33b0df1ab8006697fba7a6a49709a629055cf77\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82709 sha256=f9bf6b2cae0002099380ba52b131505a5af782ff5ca3e587c0a496c1fe6b53e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.5-py3-none-any.whl size=52603 sha256=40dfecbbf86e8397b56e9cf3bf58ab5491b7862448669825f43cd65b1a7026ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/e9/33/04db1436df0757c42fda8ea6796d7a8586e23c85fac355f476\n",
            "Successfully built htmlmin imagehash alembic databricks-cli pyLDAvis pyod umap-learn pynndescent\n",
            "Installing collected packages: tangled-up-in-unicode, smmap, scipy, multimethod, joblib, websocket-client, visions, scikit-learn, requests, python-editor, Mako, imagehash, gitdb, querystring-parser, PyYAML, pynndescent, pydantic, prometheus-flask-exporter, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, umap-learn, scikit-plot, pyod, pyLDAvis, pandas-profiling, mlxtend, mlflow, lightgbm, kmodes, imbalanced-learn, Boruta, pycaret\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Attempting uninstall: mlxtend\n",
            "    Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.1\n",
            "    Uninstalling imbalanced-learn-0.8.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Boruta-0.3 Mako-1.1.6 PyYAML-6.0 alembic-1.4.1 databricks-cli-0.16.2 docker-5.0.3 funcy-1.16 gitdb-4.0.9 gitpython-3.1.24 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 joblib-1.0.1 kmodes-0.11.1 lightgbm-3.3.1 mlflow-1.22.0 mlxtend-0.19.0 multimethod-1.6 pandas-profiling-3.1.0 phik-0.12.0 prometheus-flask-exporter-0.18.6 pyLDAvis-3.2.2 pycaret-2.3.5 pydantic-1.8.2 pynndescent-0.5.5 pyod-0.9.5 python-editor-1.0.4 querystring-parser-1.2.4 requests-2.26.0 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 smmap-5.0.0 tangled-up-in-unicode-0.1.0 umap-learn-0.5.2 visions-0.7.4 websocket-client-1.2.1\n",
            "Collecting sweetviz\n",
            "  Downloading sweetviz-2.1.3-py3-none-any.whl (15.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.1 MB 22.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (1.5.4)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (3.2.2)\n",
            "Requirement already satisfied: importlib-resources>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (5.4.0)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (4.62.3)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from sweetviz) (1.19.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.2.0->sweetviz) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.11.1->sweetviz) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->sweetviz) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->sweetviz) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.3->sweetviz) (1.15.0)\n",
            "Installing collected packages: sweetviz\n",
            "Successfully installed sweetviz-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA90sb_FDpb3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from random import randint\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYiY7eUwgY5F"
      },
      "source": [
        "# Controle de debugging\n",
        "varControl_RunExtraCode = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBEZkqvpvOMk"
      },
      "source": [
        "## Importação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX09UBAb5T3g"
      },
      "source": [
        "# importação dos dados no Github\n",
        "\n",
        "treino = pd.read_csv('https://raw.githubusercontent.com/mkunyosi/FLAI-CompeticaoML/learning/treino.csv')\n",
        "teste = pd.read_csv('https://raw.githubusercontent.com/mkunyosi/FLAI-CompeticaoML/learning/teste.csv')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "z_ZAnT1BrJRZ",
        "outputId": "fa9aa3ca-ccc4-47c0-a172-1b8f8f1c4cf8"
      },
      "source": [
        "# inspecão inicial dos dados\n",
        "treino.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Escolaridade</th>\n",
              "      <th>Entrada</th>\n",
              "      <th>Cidade</th>\n",
              "      <th>Salário</th>\n",
              "      <th>Idade</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Projeto</th>\n",
              "      <th>Experiência</th>\n",
              "      <th>Saiu</th>\n",
              "      <th>Feedbacks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2016</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>Não</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2014</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>Não</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2013</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>---</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2016</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>---</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2018</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Sim</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Escolaridade  Entrada Cidade  Salário  ... Projeto Experiência Saiu  Feedbacks\n",
              "0    Doutorado     2016  Natal        3  ...     Não           3    0          0\n",
              "1    Doutorado     2014  Natal        3  ...     Não           3    0          1\n",
              "2    Doutorado     2013  Natal        3  ...     Não           0    0          0\n",
              "3    Doutorado     2016  Natal        3  ...     Não           2    1          0\n",
              "4    Doutorado     2018  Natal        3  ...     Sim           5    1          0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW3spYZQ5jIx"
      },
      "source": [
        "## Pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tl0DQ9RVhXI"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXcnkywN6bd-"
      },
      "source": [
        "# função recursiva determinar valores de campos não preenchidos\n",
        "def reviewTarget(df, listVars, calcFunc='mean', level=0, inc=.1, verboseMode=False, sTrace=''):\n",
        "    #Idade, Entrada, Salário, Sexo, Cidade, Experiência\n",
        "    \n",
        "\n",
        "    # set prefix for debugging\n",
        "    txtPrint = \"{:<\" + str(level*4) + \"}\"\n",
        "    txtPrint = txtPrint.format(\" \")    \n",
        "    \n",
        "    # get target var\n",
        "    listTarget = listVars[0]\n",
        "    listVars.remove(listTarget)\n",
        "\n",
        "    # start list of index for all row changed    \n",
        "    allIndexChanged = []\n",
        "\n",
        "    if verboseMode: print(txtPrint, \"reviewTarget-begin\", \"level=\", level, \"vars=\", listVars)        \n",
        "    # set prefix for debugging\n",
        "    txtPrint = \"{:<\" + str(level*4 + 1) + \"}\"\n",
        "    txtPrint = txtPrint.format(\" \")\n",
        "    \n",
        "    # check recursion base\n",
        "    if df.shape[0] <= 1:\n",
        "        if verboseMode: print(txtPrint, \"recursion-base: few rows to eval\", 'n_rows=', df.shape[0]) \n",
        "        if verboseMode: print(txtPrint, \"reviewTarget-end\", \"level=\", level, \"vars=\", listVars)  \n",
        "        return -1, []\n",
        "    # there are, at least, 2 rows => go ahead\n",
        "    \n",
        "    \n",
        "    # check if there is least 1 row with null on target var and 1 row with values on target var\n",
        "    if df[listTarget].isnull().sum() == 0 or df[listTarget].notnull().sum() == 0:\n",
        "        if verboseMode: print(txtPrint, \"recursion-base: no enough data to eval\", 'n_nulls=', df[listTarget].isnull().sum(), 'n_values=',  df[listTarget].notnull().sum()) \n",
        "        if verboseMode: print(txtPrint, \"reviewTarget-end\", \"level=\", level, \"vars=\", listVars) \n",
        "        return -2, []\n",
        "    # there are, at least, 2 rows (1 null and 1 with value) => go ahead\n",
        "\n",
        "\n",
        "    if len(listVars) < 1:\n",
        "        if verboseMode: print(txtPrint, \"recursion-base: no var to filter data\", 'listVars=', listVars) \n",
        "        if verboseMode: print(txtPrint, \"reviewTarget-end\", \"level=\", level, \"vars=\", listVars) \n",
        "        return 0, []\n",
        "\n",
        "    # get first filter var from the list and sort it\n",
        "    listItem = listVars[0]             \n",
        "    listVars.remove(listItem)\n",
        "    itemsSorted = np.sort(df[listItem].unique())\n",
        "\n",
        "    localTrace = sTrace + '/' + listItem\n",
        "\n",
        "    #check number of distinct items on the new var\n",
        "    if itemsSorted.shape[0] < 1:\n",
        "        #small list => don't need to eval each item\n",
        "        #raise Exception(\"List of vars is too small. Review 'listVars' parameter.\")\n",
        "        if verboseMode: print(txtPrint, \"recursion-base: no enough data to eval\", 'listVars=', listVars) \n",
        "        if verboseMode: print(txtPrint, \"reviewTarget-end\", \"level=\", level, \"vars=\", listVars) \n",
        "        return -3, []\n",
        "    \n",
        "    #let´s eval each item on the filter var\n",
        "    for i in itemsSorted:\n",
        "\n",
        "        localTrace = localTrace + '(' + str(i) + ')'      \n",
        "          \n",
        "        df_filtered = df[df[listItem] == i].copy()         \n",
        "        \n",
        "        if verboseMode: print(txtPrint, \"Working in new data_frame \", localTrace, \">\", i)\n",
        "\n",
        "        #call recursive function to eval next var\n",
        "        if verboseMode: print(txtPrint, \"recursion(begin)...\", 'listVars=', listVars, 'item=', i)\n",
        "\n",
        "        listVarsCpy = listVars.copy()                \n",
        "        listVarsCpy.insert(0, listTarget)\n",
        "        reviewTarget_ret, recItemsChanged = reviewTarget(df_filtered, listVarsCpy, calcFunc, level+1, inc + .1, verboseMode, localTrace)\n",
        "        \n",
        "        if verboseMode: print(txtPrint, \"recursion(end): \", reviewTarget_ret, 'listVars=', listVars)\n",
        "\n",
        "        if reviewTarget_ret >=0:\n",
        "            if verboseMode: print(txtPrint, \"update local data \", recItemsChanged)\n",
        "            if len(recItemsChanged) > 0:\n",
        "                if verboseMode: print(txtPrint, \"\")\n",
        "                if verboseMode: print(txtPrint, \"len(recItemsChanged)=\", len(recItemsChanged))\n",
        "                for j in recItemsChanged:\n",
        "                    df.loc[j, listTarget] = df_filtered.loc[j, listTarget]\n",
        "                    df.loc[j, 'trace'] = df_filtered.loc[j, 'trace']\n",
        "                    allIndexChanged.append(j)\n",
        "                    if verboseMode: print(txtPrint, \"recItemsChanged=\", j, ' newValue=', df.loc[j, listTarget])\n",
        "\n",
        "            \n",
        "        \n",
        "            #set mean for other data\n",
        "            if verboseMode: print(txtPrint, 'mean/mode calculus', 'type=', calcFunc, 'len(sample)=', len(df_filtered[listTarget]))\n",
        "            #targetMean = round(np.mean(df_filtered[listTarget]),0) #+ inc\n",
        "            if calcFunc == 'mean':\n",
        "                targetMean = pd.to_numeric(round(np.mean(df_filtered[listTarget]),0), downcast='integer') #int(round(np.mean(df_filtered[listTarget]),0) )\n",
        "            elif calcFunc == 'mode':\n",
        "                targetMean = df_filtered[df_filtered['Projeto-new'].notna()]['Projeto-new'].mode()[0]\n",
        "                #print('targetMean', targetMean)\n",
        "                     \n",
        "            else:\n",
        "                if verboseMode: print(txtPrint, \"invalid function\", calcFunc) \n",
        "                return -4, []\n",
        "            \n",
        "\n",
        "            for j in df_filtered['Index']:\n",
        "                if calcFunc == 'mean':\n",
        "                    if pd.isna(df_filtered.loc[j, listTarget]):                                    \n",
        "                        df.loc[j, listTarget] = pd.to_numeric(targetMean, downcast='integer') #int(targetMean )\n",
        "                        df.loc[j, 'trace'] = ' idx=' + str(j) + 'mean=' + str(targetMean+ inc) + ' trace:' + sTrace\n",
        "                        allIndexChanged.append(j)\n",
        "                elif calcFunc == 'mode':\n",
        "                    if pd.isna(df_filtered.loc[j, listTarget]):                \n",
        "                        df.loc[j, listTarget] = targetMean \n",
        "                        df.loc[j, 'trace'] = ' idx=' + str(j) + 'mode=' + targetMean + str(inc) + ' trace:' + sTrace\n",
        "                        allIndexChanged.append(j)\n",
        "\n",
        "\n",
        "\n",
        "            if verboseMode: print(txtPrint, \"targetMean=\", targetMean, 'listTarget=',listTarget, ' index-upd=', allIndexChanged)\n",
        "\n",
        "\n",
        "    if verboseMode: print(txtPrint, \"reviewTarget-end\", \"level=\", level, \"vars=\", listVars) \n",
        "\n",
        "    return 0, allIndexChanged"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44LesPhbQfqM"
      },
      "source": [
        "# target var: adjust values \n",
        "def evalTargetVar(df, targetVar, mode='hard', tiebreaker=0):\n",
        "\n",
        "    targetAux = targetVar + '-new'\n",
        "\n",
        "    for k in treino_new['Index']:\n",
        "        if df.loc[k, 'action'] != \"keep\":\n",
        "            df.loc[k, targetAux] = df.loc[k, 'Saiu']\n",
        "        else:\n",
        "            sum_0s = df.loc[k, '0s']\n",
        "            sum_1s = df.loc[k, '1s']\n",
        "            rowRef = df.loc[k, 'ref']\n",
        "            if mode == 'hard':\n",
        "                if sum_0s > sum_1s: newSet = 0\n",
        "                elif sum_0s < sum_1s: newSet = 1\n",
        "                elif tiebreaker == 0: newSet = 0\n",
        "                elif tiebreaker == 1: newSet = 1\n",
        "                else:\n",
        "                    raise Exception(\"invalid tiebreaker:\", tiebreaker)\n",
        "\n",
        "                df.loc[k, targetAux] = newSet\n",
        "\n",
        "                df[targetAux] = pd.to_numeric(df[targetAux], downcast='integer')\n",
        "                                               \n",
        "            elif mode == 'soft':\n",
        "                if sum_0s == 0 and sum_1s == 0: newSet = 0.5\n",
        "                else: newSet = sum_1s/(sum_0s + sum_1s)\n",
        "\n",
        "                df.loc[k, targetAux] = newSet\n",
        "            else:\n",
        "                raise Exception(\"invalid mode:\", mode)    \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H_0TDAklYhD"
      },
      "source": [
        "### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaerAEt06bDI"
      },
      "source": [
        "# Criação de features auxiliares para não alterar os dados originais\n",
        "#\n",
        "# Escolaridade-new: Cópia de Escolaridade e categorização de '---' para 'not PhD'\n",
        "# Idade           : conversão de texto para número\n",
        "# Idade-new       : Cópia de Idade\n",
        "# Projeto-new     : Cópia de Projeto\n",
        "# Index           : Índice para marcar as linhas (provavelmente tenha alguma forma mais limpa para ter acesso ao índice do elemento) \n",
        "treino[\"Escolaridade-new\"] = treino[\"Escolaridade\"].map(lambda x: x if x == \"Doutorado\" else \"not PhD\")\n",
        "treino[\"Idade\"] = treino[\"Idade\"].map(lambda x: np.nan if x == \"---\" else pd.to_numeric(int(x), downcast='integer'))\n",
        "treino[\"Idade-new\"] = treino[\"Idade\"].map(lambda x: x)\n",
        "treino[\"Projeto-new\"] = treino[\"Projeto\"].map(lambda x: np.nan if x == \"---\" else x)\n",
        "treino['Index'] = range(treino.shape[0])\n",
        "\n",
        "teste[\"Escolaridade-new\"] = teste[\"Escolaridade\"].map(lambda x: x if x == \"Doutorado\" else \"not PhD\")\n",
        "teste[\"Idade\"] = teste[\"Idade\"].map(lambda x: np.nan if x == \"---\" else pd.to_numeric(int(x), downcast='integer'))\n",
        "teste[\"Idade-new\"] = teste[\"Idade\"].map(lambda x: x)\n",
        "teste[\"Projeto-new\"] = teste[\"Projeto\"].map(lambda x: np.nan if x == \"---\" else x)\n",
        "teste['Index'] = range(teste.shape[0])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze9gpS1I6sUj"
      },
      "source": [
        "#Acertar valores faltantes em 'Idade-new'\n",
        "retCode, rowsChanged = reviewTarget(treino, [\"Idade-new\", \"Entrada\", \"Salário\", \"Sexo\", \"Cidade\", \"Experiência\"], calcFunc='mean', verboseMode=False)\n",
        "\n",
        "retCode, rowsChanged = reviewTarget(teste, [\"Idade-new\", \"Entrada\", \"Salário\", \"Sexo\", \"Cidade\", \"Experiência\"], calcFunc='mean', verboseMode=False)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlbezEtXxPef"
      },
      "source": [
        "#Acertar valores faltantes em 'Projeto-new'\n",
        "retCode, rowsChanged = reviewTarget(treino, [\"Projeto-new\", \"Entrada\", \"Salário\", \"Sexo\", \"Cidade\", \"Experiência\"], calcFunc='mode', verboseMode=False)\n",
        "\n",
        "retCode, rowsChanged = reviewTarget(teste, [\"Projeto-new\", \"Entrada\", \"Salário\", \"Sexo\", \"Cidade\", \"Experiência\"], calcFunc='mode', verboseMode=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXrfqsDB5yfb",
        "outputId": "339c7221-0efd-4282-9071-2f536e5ac97d"
      },
      "source": [
        "# identify similar rows and clean them\n",
        "\n",
        "treino_new = pd.DataFrame()\n",
        "teste_new = pd.DataFrame()\n",
        "\n",
        "lstFrom = [ 'Index', 'Escolaridade-new', 'Entrada',\t'Cidade', 'Salário','Idade-new', 'Sexo', 'Projeto-new', 'Experiência', 'Feedbacks', 'Saiu'] #\t\t\t'Index'\t'trace'\t'Projeto-new']\n",
        "lstVars = ['Index', 'Escolaridade', 'Entrada',\t'Cidade', 'Salário','Idade', 'Sexo', 'Projeto', 'Experiência', 'Feedbacks', 'Saiu']\n",
        "\n",
        "for i in range(len(lstVars)):\n",
        "    treino_new[lstVars[i]] = treino[lstFrom[i]]\n",
        "for i in range(len(lstVars)-1):\n",
        "    teste_new[lstVars[i]] = teste[lstFrom[i]]\n",
        "\n",
        "treino_dup = treino_new[treino_new.drop(['Index', 'Saiu'], axis=1).duplicated()].copy()\n",
        "\n",
        "for i in treino_dup['Index']:\n",
        "    rows_result = treino_new\n",
        "    row = treino_dup[treino_dup['Index'] == i]\n",
        "    for k in lstVars:\n",
        "        if k not in ['Index', 'Saiu']:\n",
        "          rows_result = rows_result[  rows_result[k] == treino_dup.loc[i][k]          ]\n",
        "    \n",
        "    sum_1s = rows_result['Saiu'].sum()\n",
        "    sum_0s = rows_result['Saiu'].shape[0] - sum_1s\n",
        "    rowRef = rows_result['Index'].min()\n",
        "    for k in rows_result['Index']:\n",
        "        treino_new.loc[k, '0s'] = sum_0s\n",
        "        treino_new.loc[k, '1s'] = sum_1s\n",
        "        treino_new.loc[k, 'ref'] = rowRef\n",
        "        treino_new.loc[k, 'action'] = \"keep\" if rowRef == k else \"del\"        \n",
        "\n",
        "#clean duplicate rows\n",
        "print('shape-orig: ', treino_new.shape)\n",
        "treino_new.drop(treino_new[treino_new['action'] == 'del'].index, inplace = True)\n",
        "print('shape-clean: ', treino_new.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape-orig:  (2916, 15)\n",
            "shape-clean:  (2102, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HJeCukItQ_7s",
        "outputId": "23d89b9b-400a-42a7-daea-7cd1322532b8"
      },
      "source": [
        "evalTargetVar(treino_new, targetVar='Saiu',mode='hard', tiebreaker=0)\n",
        "treino_new"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Escolaridade</th>\n",
              "      <th>Entrada</th>\n",
              "      <th>Cidade</th>\n",
              "      <th>Salário</th>\n",
              "      <th>Idade</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Projeto</th>\n",
              "      <th>Experiência</th>\n",
              "      <th>Feedbacks</th>\n",
              "      <th>Saiu</th>\n",
              "      <th>0s</th>\n",
              "      <th>1s</th>\n",
              "      <th>ref</th>\n",
              "      <th>action</th>\n",
              "      <th>Saiu-new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2016</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>Não</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2014</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>36.0</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>Não</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2013</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2016</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>keep</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2018</td>\n",
              "      <td>Natal</td>\n",
              "      <td>3</td>\n",
              "      <td>34.0</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Sim</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>2908</td>\n",
              "      <td>Doutorado</td>\n",
              "      <td>2014</td>\n",
              "      <td>João Pessoa</td>\n",
              "      <td>3</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2909</th>\n",
              "      <td>2909</td>\n",
              "      <td>not PhD</td>\n",
              "      <td>2015</td>\n",
              "      <td>João Pessoa</td>\n",
              "      <td>2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>Não</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2910</th>\n",
              "      <td>2910</td>\n",
              "      <td>not PhD</td>\n",
              "      <td>2014</td>\n",
              "      <td>Recife</td>\n",
              "      <td>3</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>2913</td>\n",
              "      <td>not PhD</td>\n",
              "      <td>2016</td>\n",
              "      <td>Recife</td>\n",
              "      <td>3</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>Sim</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2915</th>\n",
              "      <td>2915</td>\n",
              "      <td>not PhD</td>\n",
              "      <td>2017</td>\n",
              "      <td>João Pessoa</td>\n",
              "      <td>2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>Não</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2102 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Index Escolaridade  Entrada       Cidade  ...   1s  ref action Saiu-new\n",
              "0         0    Doutorado     2016        Natal  ...  NaN  NaN    NaN      0.0\n",
              "1         1    Doutorado     2014        Natal  ...  NaN  NaN    NaN      0.0\n",
              "2         2    Doutorado     2013        Natal  ...  NaN  NaN    NaN      0.0\n",
              "3         3    Doutorado     2016        Natal  ...  1.0  3.0   keep      0.0\n",
              "4         4    Doutorado     2018        Natal  ...  NaN  NaN    NaN      1.0\n",
              "...     ...          ...      ...          ...  ...  ...  ...    ...      ...\n",
              "2908   2908    Doutorado     2014  João Pessoa  ...  NaN  NaN    NaN      0.0\n",
              "2909   2909      not PhD     2015  João Pessoa  ...  NaN  NaN    NaN      1.0\n",
              "2910   2910      not PhD     2014       Recife  ...  NaN  NaN    NaN      0.0\n",
              "2913   2913      not PhD     2016       Recife  ...  NaN  NaN    NaN      0.0\n",
              "2915   2915      not PhD     2017  João Pessoa  ...  NaN  NaN    NaN      1.0\n",
              "\n",
              "[2102 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YogaiNex6FcK",
        "outputId": "b4776d87-d522-4e28-d955-1bae21b8377f"
      },
      "source": [
        "#checking changes\n",
        "#C = np.where(cond, A, B)\n",
        "treino_new['\"Saiu\" x \"Saiu-new\"'] = np.where(treino_new['Saiu'] == treino_new['Saiu-new'], True, False)\n",
        "treino_new[treino_new['\"Saiu\" x \"Saiu-new\"'] == False].shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSyoqHETVaTk"
      },
      "source": [
        "# acertar o valor da variável Saiu\n",
        "treino_new['Saiu-old'] = treino_new['Saiu']\n",
        "treino_new['Saiu'] = treino_new['Saiu-new']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8PDEdCdUMXr"
      },
      "source": [
        "## My Machine learning - Kunyosi's algorithm 🤓"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W80H61lnGUY6"
      },
      "source": [
        "# find neighbors for a entry\n",
        "def findNeighbors(df, entry, idxEntry, lstFilters, varTarget,         verboseMode=False):\n",
        "    # set prefix for debugging\n",
        "    txtPrint = \"{:<\" + str(0) + \"}\"\n",
        "    txtPrint = txtPrint.format(\" \")\n",
        "\n",
        "    if verboseMode: print(txtPrint, \">>>findNeighbors-begin>>>\", \"lstConstraints=\", lstConstraints)      \n",
        "\n",
        "    varFilters_cpy = lstFilters.copy()\n",
        "\n",
        "    idx_neighbors = []\n",
        "    value_targets = []\n",
        "\n",
        "    localEntry = entry \n",
        "\n",
        "    for i in varFilters_cpy:\n",
        "        localEntry_value = localEntry.loc[idxEntry, i]\n",
        "        if verboseMode: print(txtPrint, 'filter=', i, 'localEntry.shape=', localEntry.shape)\n",
        "        if verboseMode: print(txtPrint, 'value=', localEntry_value) #localEntry.head(1)[i][1])\n",
        "        res = df[  df[i] == localEntry_value   ]\n",
        "        \n",
        "        if verboseMode: print(txtPrint, 'shape=', res.shape[0])\n",
        "        if res.shape[0] > 1:\n",
        "            df = res\n",
        "    \n",
        "    if df.shape[0] <= 0:\n",
        "        #no fields for eval\n",
        "        idx_neighbors = []\n",
        "    else:\n",
        "        #group neighbors\n",
        "        if verboseMode: print(txtPrint, 'build list for neighbors')\n",
        "        for i in df.index:\n",
        "            idx_neighbors.append(i)\n",
        "            if verboseMode: print(txtPrint, 'ref=', i)\n",
        "            if verboseMode: print(txtPrint, 'target value=', df.loc[i][varTarget])\n",
        "            value_targets.append(df.loc[i][varTarget])\n",
        "\n",
        "    \n",
        "    if verboseMode: print(txtPrint, \"<<<findNeighbors-end<<<\")    \n",
        "    return idx_neighbors, value_targets    \n",
        "    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKl7QTP_G0tE"
      },
      "source": [
        "# Teste da função findNeighbors\n",
        "if varControl_RunExtraCode:\n",
        "    lstConstraints = ['Entrada', 'Salário', 'Sexo', 'Cidade','Idade', 'Experiência']  #, 'Projeto', 'Feedbacks', 'Escolaridade']\n",
        "\n",
        "    y_test = teste_new #[teste_new['Index'] == 1].copy()\n",
        "    y_test_idx = 10\n",
        "\n",
        "    nb_list, target_list = findNeighbors(treino_new, y_test, y_test_idx, lstConstraints, 'Saiu', verboseMode=True)\n",
        "    print(nb_list)\n",
        "    print(target_list)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTRToj9-bwhp"
      },
      "source": [
        "#running my ML\n",
        "\n",
        "def myPredict(X, y, varList, lstConstraints,         verboseMode=False):\n",
        "\n",
        "    # set prefix for debugging\n",
        "    #txtPrint = \"{:<\" + str(level*4) + \"}\"\n",
        "    txtPrint = \"{:<\" + str(0) + \"}\"\n",
        "    txtPrint = txtPrint.format(\" \")\n",
        "\n",
        "    if verboseMode: print(txtPrint, \"myPredict-begin\", \"varList=\", varList, \"lstConstraints=\", lstConstraints)      \n",
        "\n",
        "    pred = []\n",
        "    backlog = []\n",
        "\n",
        "    XCopy = X.copy()\n",
        "\n",
        "    varList_cpy = varList.copy()\n",
        "    vTarget = varList_cpy[0]\n",
        "    varList_cpy.remove(vTarget)\n",
        "\n",
        "    ##for i in range(XCopy.shape[0]):\n",
        "    XCopy['myIdx'] = XCopy.index\n",
        "\n",
        "    yLen = y.shape[0] \n",
        "\n",
        "    \n",
        "    for i in range(yLen):\n",
        "        if i % 500 == 0: print('myPredict count=', i, '/', yLen)\n",
        "\n",
        "\n",
        "        #test: pred.append(randint(0, 1))\n",
        "        # step 1: search the same pattern on X\n",
        "        df = XCopy\n",
        "\n",
        "        if verboseMode: print(txtPrint, \"\")\n",
        "        if verboseMode: print(txtPrint, 'y', y.loc[i])\n",
        "        for j in varList_cpy:\n",
        "            df = df[  df[j] == y.loc[i][j]          ]\n",
        "            #print('shape-step:', j , df.shape)\n",
        "            #if j not in ['Index', 'Saiu']:\n",
        "\n",
        "        if verboseMode: print(txtPrint, 'shape-end' , df.shape)\n",
        "        if df.shape[0] == 0:\n",
        "            #not found\n",
        "            #y_test = teste_new[teste_new['Index'] == 1].copy()\n",
        "            #print(y.loc[i])\n",
        "            #entry = y[y['Index'] == i].copy()\n",
        "            #print(txtPrint, 'entry', entry) \n",
        "            nb_list, target_list = findNeighbors(treino_new, y, i, lstConstraints, vTarget, verboseMode)\n",
        "            #print(\"***\")\n",
        "            sum_0s = 0\n",
        "            sum_1s = 0\n",
        "            for k in target_list:\n",
        "              if k == 0: sum_0s += 1\n",
        "              elif k == 1: sum_1s += 1\n",
        "              else: sum_1s = sum_1s  \n",
        "            \n",
        "            voting = 0 if sum_0s >= sum_1s else 1\n",
        "            pred.append(voting)\n",
        "            backlog.append(nb_list)\n",
        "        else:\n",
        "            for k in range(df.shape[0]):\n",
        "              if verboseMode: print(txtPrint, '   idx=', df.index[k])\n",
        "              if verboseMode: print(txtPrint, '   dataframe')\n",
        "              if verboseMode: print(txtPrint, XCopy.loc[df.index[k]]) #, df.loc[i, 'myIdx']])\n",
        "            pred.append(XCopy.loc[df.index[k], vTarget])\n",
        "            backlog.append(df.index[k])         \n",
        "              \n",
        "\n",
        "\n",
        "    if verboseMode: print(txtPrint, \"myPredict-end\", \"pred=\", pred)\n",
        "    if verboseMode: print(txtPrint, \"myPredict-end\", \"backlog=\", backlog)\n",
        "\n",
        "\n",
        "    return pred, backlog"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Pw25BgUmuM"
      },
      "source": [
        "## Running ML model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU0aje9zdIow",
        "outputId": "c74e57cc-3e68-4978-b7c7-214123c6ef67"
      },
      "source": [
        "lstVars = ['Saiu', 'Escolaridade', 'Entrada',\t'Cidade', 'Salário','Idade', 'Sexo', 'Projeto', 'Experiência', 'Feedbacks']\n",
        "lstConstraints = ['Entrada', 'Salário', 'Sexo', 'Cidade','Idade', 'Experiência']  #, 'Projeto', 'Feedbacks', 'Escolaridade']\n",
        "\n",
        "y_test = teste_new #.head(5).copy()\n",
        "pred, bklog = myPredict(treino_new, y_test, lstVars, lstConstraints, verboseMode=False)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "myPredict count= 0 / 1737\n",
            "myPredict count= 500 / 1737\n",
            "myPredict count= 1000 / 1737\n",
            "myPredict count= 1500 / 1737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yFenlFRlBFh"
      },
      "source": [
        "## Exporting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogA9lNCwVJ6F",
        "outputId": "3a035b5b-8896-4605-c4f9-fd15147ae516"
      },
      "source": [
        "subm_myPred = pd.DataFrame()\n",
        "\n",
        "for i in range(len(pred)):\n",
        "  subm_myPred.loc[i, 'Saiu'] = \"{:.0f}\".format(pred[i])\n",
        "  #subm_myPred.loc[i, 'Log'] = str(bklog[i])\n",
        "\n",
        "print(subm_myPred.shape)\n",
        "subm_myPred.to_csv('subm_myPred.csv', index = False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1737, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "Eg1Kh9rwXWxM",
        "outputId": "3c81f7f8-d9f8-4ab8-a62a-912807e2f357"
      },
      "source": [
        "# Essa predição gerou um F1-Score = 0,80622\n",
        "subm_myPred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Saiu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1732</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1733</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1734</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1735</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1737 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Saiu\n",
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       1\n",
              "...   ...\n",
              "1732    0\n",
              "1733    1\n",
              "1734    1\n",
              "1735    0\n",
              "1736    0\n",
              "\n",
              "[1737 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}